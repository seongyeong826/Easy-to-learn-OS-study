# CHAPTER 10 입출력 시스템과 저장장치

참고: [입출력 시스템과 저장장치](https://velog.io/@lil_young/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C-Chapter-11.-%EC%9E%85%EC%B6%9C%EB%A0%A5-%EC%8B%9C%EC%8A%A4%ED%85%9C%EA%B3%BC-%EC%A0%80%EC%9E%A5%EC%9E%A5%EC%B9%98)

# 입출력 시스템

## 입출력장치와 채널

주변장치는 데이터 전송 속도에 따라 두 가지로 나뉜다.

- 저속 주변장치: 메모리와 주변장치 사이에 오고 가는 데이터의 양이 적어 데이터 전송률이 낮은 장치이다. Ex:) 키보드
- 고속 주변장치: 메모리와 주변장치 사이에 대용량의 데이터가 오고 가므로 데이터 전송률이 높은 장치이다. Ex:) 그래픽카드, 하드디스크

속도가 비슷한 장치끼리 같은 채널을 사용하면, 여러 채널을 효율적으로 사용할 수 있다.

## 입출력 버스의 구조

폴링 → 입출력 제어기 → `입출력 버스 분리와 그래픽카드 분리`의 순서로 발전한다.

### **폴링**

<aside>

💡 **폴링(Polling)**

CPU가 작업을 진행하다가 입출력 명령을 만나면 직접 입출력장치에서 데이터를 가져오는 것이다. 이 방식을 적용하면 CPU는 입출력이 끝날 때까지 다른 작업을 할 수 없다.

</aside>

초기에는 주변장치가 많지 않았고 CPU와 메모리의 속도도 빠르지 않았다. 그래서 모든 장치가 하나의 버스로 연결되어 있었고 입출력에 `폴링` 방식을 사용했다.

### 입출력 제어기

컴퓨터 기술이 발전하면서 CPU와 메모리 성능이 급격히 향상되고 주변장치의 종류도 다양해졌다. 이러한 변화에 따라 CPU가 폴링 방식으로 주변장치를 관리하기 어려워져서 모든 입출력을 입출력 제어기(I/O Controller)에 맡기는 구조로 바뀌었다.

<aside>

💡 **I/O Controller**

메인 버스와 입출력 버스로 나뉜다. 메인 버스는 고속으로 작동하는 CPU와 메모리가 사용하고, 입출력 버스는 주변장치가 사용한다. CPU에서 입출력 요청이 오면 I/O Controller는 입출력장치로부터 데이터를 직접 송수신한다. 이를 통해 느린 입출력장치로 인해 CPU와 메모리의 작업이 느려지는 것을 막을 수 있어 전체 작업 효율이 향상된다.

</aside>

### 입출력 버스 분리

I/O Controller를 사용하면 작업 효율을 높일 수 있지만, 저속 주변장치 때문에 고속 주변장치의 데이터 전송이 느려질 수 있다. 예를 들어, 그래픽카드 같은 장치와 키보드 같은 장치가 입출력 버스를 공유하면 입출력 속도가 현저히 저하되는 것이다. 이러한 문제를 해결하기 위해 입출력 버스를 고속 입출력 버스와 저속 입출력 버스로 분리하여 운영한다. 두 버스 사이의 데이터 전송은 채널 선택기가 관리한다.

### 입출력 버스로부터 그래픽카드 분리

초기의 그래픽카드는 단순히 데이터를 화면에 출력하는 기능만 했다. 그러나 화면의 해상도가 높아지고 3D 게임이 보급되면서 그래픽카드가 계산해야 하는 양이 늘어남에 따라 그래픽카드에 GPU가 부착되었다.

GPU의 계산 능력과 다루는 데이터의 양은 고속 입출력 버스로 감당하기 어려운 수준이어서, 입출력 버스에서 분리하고 메인버스와 직접 연결된 그래픽 버스를 사용하게 되었다.

## DMA(직접 메모리 접근)

<aside>

💡 **DMA**

CPU의 도움 없이도 메모리에 접근할 수 있도록 I/O Controller에 부여된 권한이다.

</aside>

### 입출력 제어기

입출력 제어기

여러 채널에 연결된 주변장치로부터 전송된 데이터를 적절히 배분하여 하나의 데이터 흐름을 만든다. 이때 채널 선택기는 여러 채널에서 전송된 데이터 중 어떤 것을 메모리로 보낼지 결정한다. 이렇게 주변장치에서 전송된 데이터는 DMA 제어기를 거쳐 메모리에 올라간다. 반대로 메모리에서 주변장치로 데이터를 전송할 때는 DMA 제어기가 메모리에서 데이터를 가져오면 채널 선택기에서 적당한 채널로 전송한다.

메인 메모리는 CPU가 작업하는 전용 공간이다. 그런데 DMA 제어기가 입출력장치에서 가져온 데이터 혹은 입출력장치로 가져갈 데이터가 있을 때도 이 공간을 사용한다. 즉 CPU의 작업 공간과 DMA의 작업 공간이 겹치는 것이다. 이를 방지하기 위해 과거에는 DMA 제어기가 전송하는 데이터를 `입출력 메모리` 라는 별도의 메모리에 보관했으나, 이 방식은 입출력 메모리에서 다시 메인 메모리로 데이터를 옮기는 불필요한 작업을 수반했다.

오늘날에는 CPU가 작업하는 공간과 DMA 제어기가 데이터를 옮기는 공간을 분리하여 메인메모리를 운영하는 `메모리 맵 입출력 방식`을 사용한다. 이 방식에서는 메인 메모리의 주소 공간 중 일부를 DMA 제어기에 할당하여 작업 공간이 겹치는 것을 막는다.

## 인터럽트

- 주변장치의 입출력 요구나 하드웨어의 이상 현상을 CPU에 알려주는 역할을 하는 신호
- 시스템 내에는 100개가 넘는 인터럽트가 있다.
- 인터럽트는 한 번에 하나가 발생하기도 하고 여러 개가 발생하기도 한다.

### 인터럽트 종류

| 종류 | 발생 원인 | 비고 |
| --- | --- | --- |
| 외부 인터럽트 | 입출력 및 하드웨어 | 주변장치 변화, 하드웨어 이상 |
| 내부 인터럽트 | 프로세스의 오류(divide by 0, 자신의 메모리 공간을 벗어난 작업) | 예외 상황 인터럽트 |
| 시그널(사용자 인터럽트) | 사용자의 요청(Ctrl+C, kill 명령어) | 자발적 인터럽트 |

### 인터럽트 벡터, 인터럽트 핸들러

<aside>

💡 **인터럽트 벡터**

여러 인터럽트 중 어떤 인터럽트가 발생했는지 파악하기 위해 사용하는 자료 구조로, 인터럽트 벡터의 값이 1이면 해당 인터럽트가 발생했다는 의미이다.

</aside>

<br>

<aside>

💡 **인터럽트 핸들러**

인터럽트의 처리 방법을 함수 형태로 만들어놓은 것이다. 운영체제는 인터럽트가 발생하면 인터럽트 핸들러를 호출하여 작업한다. 인터럽트 벡터에는 해당하는 인터럽트 핸들러를 호출할 수 있도록 인터럽트 핸들러가 저장된 메모리의 주소가 포인터 형태로 등록되어 있다.
사용자 인터럽트인 시그널의 경우 자신의 만든 인터럽트 핸들러를 등록할 수 있다.

</aside>

## 버퍼

- **속도가 다른 두 장치의 속도 차이를 완화하는 역할**
- 느린 장치를 통해 들어오는 데이터를 버퍼에 모아 한꺼번에 이동하면 효율적이다.
- 대부분의 **입출력장치**(하드디스크, 키보드 등)는 버퍼를 사용하여 느린 속도를 보완한다.
- **커널**에서도 버퍼를 사용한다. 커널이 입출력장치로 보내야 할 데이터를 버퍼에 담아놓으면 입출력 제어기가 커널 버퍼에서 입출력장치로 데이터를 보낸다. 커널이 버퍼를 사용하면 입출력 작업이 완료되기 전에 다른 작업을 할 수 있어 시스템의 성능이 좋아진다.
- 프린터의 **스풀러**도 비슷하다. 스풀러를 사용하면 출력할 데이터를 스풀러로 보내고 다른 작업을 할 수 있다.

### 단일 버퍼 VS 이중 버퍼

- 단일 버퍼를 사용하면 데이터를 버퍼에 담는 작업과 버퍼에 있는 데이터를 퍼 가는 작업을 동시에 하기 어렵다.
- 이중 버퍼를 사용하면 한 버퍼는 데이터를 담는 용도로 쓰고 또 한 버퍼는 데이터를 가져가는 용도로 쓸 수 있어 유용하다.

### 버퍼 운용 시 주의점

**원인**

시스템의 효율성을 위해 운영체제는 기본적으로 버퍼가 꽉 찼을 때만 입출력장치로 데이터를 전송하도록 설계되어 있다. 버퍼에 데이터가 꽉 차 있지 않으면 일정 시간이 흐른 후에야 데이터를 전송한다.

**해결 방법**

- USB 메모리를 사용할 때 하드웨어 안전 제거를 사용하면 플러시(버퍼가 다 차지 않아도 강제로 버퍼의 내용이 저장장치로 옮겨지는 것으로, 플러시가 일어나면 저장장치의 손상을 방지하기 위해 입출력장치의 전원이 차단된다.)가 일어나서 버퍼의 데이터가 정상적으로 저장된다. → 플러시를 사용하지 않으면 버퍼 안의 데이터가 USB에 전송되지 않은 채로 USB가 제거될 수 있다.
- 프로그래밍 중 파일 입출력 시 버퍼에만 있고 저장장치에는 반영되지 않는 경우가 있다. 이를 방지하기 위해 유닉스의 fflush와 같은, 버퍼의 내용을 강제로 저장장치로 옮기는 명령어가 있다.
- 모니터로의 출력이 이상하게 되는 것을 방지하기 위해 모니터 출력 시 줄바꿈 문자를 넣는 것이 좋다.

<br>

# 디스크 장치

## 하드디스크

- Moving-Head Hard Disk Drive, 즉, 움직이는 헤드를 가진 하드디스크 드라이브이다.
- 원반을 사용한 저장장치로, 맨 앞에 있는 데이터나 맨 뒤에 있는 데이터에 접근하는 속도가 거의 비슷하여 수많은 시스템에서 도입했다.
- 같은 용량의 메인 메모리보다 훨씬 싸고 데이터도 반영구적으로 저장할 수 있다.

### 하드디스크의 구조

- 플래터: 표면에 자성체가 발려 있어 자기를 이용하여 0과 1 데이터를 저장할 수 있다.
- 섹터와 블록: 섹터는 하드디스크의 가장 작은 저장 단위이다. 하나의 섹터에는 한 덩어리의 데이터가 저장된다. 블록은 하드디스크와 컴퓨터 사이에 데이터를 전송하는 논리적인 저장 단위 중 가장 작은 단위이다. 블록은 여러 개의 섹터로 구성되며, 윈도우즈에서는 클러스터라고 표현한다. 메모리에서는 물리적으로 하나의 바이트마다 주소가 배정되지만, 하드디스크에서는 논리적인 단위인 블록마다 주소가 배정된다. 즉, 하드디스크 입장에서는 섹터가 가장 작은 저장 단위이지만, 운영체제 입장에서는 하드디스크와 데이터를 주고받을 때 블록이 가장 작은 단위이다.
- 트랙과 실린더: 트랙은 플래터에서 회전축을 중심으로 데이터가 기록되는 동심원, 즉 동일한 동심원상에 있는 섹터의 집합을 말한다. 헤드는 여러 플래터의 같은 위치에 있는 트랙을 동시에 읽거나 쓸 수 있다. 여러 개의 플래터에 있는 같은 트랙의 집합을 실린더라고 한다.
- 헤드와 플래터: 하드디스크에서 데이터를 읽거나 쓸 때는 읽기/쓰기 헤드를 사용한다. 헤드의 수는 데이터가 저장되는 플래터의 표면 수와 같다. 만약 헤드가 플래터에 붙어버리면 플래터의 표면에 상처가 생길 수 있는데, 이를 배드 섹터라고 한다.

## CD

- 트랙과 섹터로 구성되며, 수평으로 움직이는 헤드가 트랙 사이를 움직이면서 데이터를 읽는다.
- 표면에 미세한 홈이 파여 있어 헤드에서 발사된 레지어가 홈에 들어가 반사되지 않으면 0으로, 반사되어 돌아오면 1로 인식한다.

## 하드디스크 VS CD

둘 다 원반을 사용하지만 구동 방식이 다르다

### 디스크 장치의 회전 비교

하드디스크: 하드디스크의 플래터는 항상 일정한 속도로 회전하여 바깥쪽 트랙의 속도가 안쪽 트랙의 속도보다 훨씬 빠르다. 그러므로 가장 바깥쪽에 있는 섹터가 가장 안쪽에 있는 섹터보다 더 크다. 일정한 시간 동안 이동한 각도가 같다는 의미에서 이를 **각속도 일정 방식**이라고 한다.

CD: 어느 트랙에서나 단위 시간당 디스크의 이동 거리가 같은데, 이를 구현하려면 헤드가 안쪽 트랙에 있을 때는 디스크의 회전 속도를 빠르게 하고, 헤드가 바깥쪽 트랙으로 이동했을 때는 디스크의 회전 속도를 느리게 해야 한다. 이것을 선속도 일정 방식이라고 한다.

### 디스크 장치의 섹터 비교

하드디스크: 트랙마다 속도가 다르기 때문에 섹터의 크기도 다르다.

CD: 모든 트랙의 움직이는 속도가 같고 섹터의 크기도 같다.

## 디스크 장치의 데이터 전송 과정

### 데이터 전송 시간

탐색 시간 + 회전 지연 시간 + 전송 시간

### 데이터 전송 순서

1. 탐색 시간: 하드디스크의 특정 섹터에 저장된 데이터를 읽거나 쓰려면 그 섹터가 있는 트랙까지 헤드가 이동해야 한다. 탐색 시간은 헤드가 현재 위치에서 그 트랙까지 이동하는 데 걸리는 시간이다.
2. 회전 지연 시간: 특정 트랙까지 이동한 헤드는 플래터가 회전하여 원하는 섹터를 만날 때까지 기다린다. 회전 지연 시간은 원하는 섹터를 만날 때까지 회전하는 데 걸리는 시간이다.
3. 전송 시간: 헤드가 원하는 섹터에 있는 데이터를 읽어 전송하는 데 걸리는 시간이다.

## 디스크 장치 관리

### 파티션

- 파티션은 디스크를 논리적으로 분할하는 작업이다.
- 보통은 파티션 하나에 하나의 파일 시스템이 탑재된다.

### 포매팅

- 파티션이 결정되면 포매팅을 한다.
- 디스크에 파일 시스템을 탑재하고 디스크 표면을 초기화하여 사용할 수 있는 형태로 만드는 작업이다.

### 조각 모음

- 파티션을 나누고 포매팅을 한 후 하드디스크를 사용하다 보면 점점 느려지는 경우가 많은데, 이것은 파일을 저장했다 지우는 과정에서 빈 공간이 생기는 조각화(단편화) 때문이다.
- 하드디스크는 주기적으로 이러한 조각들을 모아주는 조각 모음을 해줘야 한다. 반도체를 이용한 USB나 SSD는 조각 모음을 하지 않아도 성능 차이가 없다.

## 네트워크 저장장치

### DAS

- 서버와 같은 컴퓨터에 직접 연결된 저장장치
- 대표적인 예로 윈도우의 파일 공유가 있다.
- 컴퓨터의 메인보드에 있는 입출력 버스와 연결된다.
- 컴퓨터에 직접 연결된 저장장치를 사용하기 때문에 다른 운영체제가 쓰는 파일 시스템을 사용할 수 없다.
- 데이터 관리나 백업을 사용자가 직접 해야 한다.

### NAS

- 기존의 저장장치를 LAN이나 WAN에 붙여서 사용하는 방식
- NAS 전용 운영체제를 가진 독립적인 장치로 새로운 하드디스크를 추가하거나 뺄 수 있다.
- 저장장치를 네트워크상에 두고 여러 클라이언트가 네트워크를 통해 접근하게 함으로써 공유 데이터의 관리 및 데이터의 중복 회피가 가능하다.
- 사용자 인터페이스를 이용하여 다양한 파일 관리가 가능하도록 구현되었다.
- 대표적인 예로 무선 공유기에 연결된 프린터는 컴퓨터나 스마트폰과 유선으로 연결하지 않아도 출력이 가능하다.

### SAN

- NAS보다 진보된 형태의 네트워크 저장장치
- 데이터 서버, 백업 서버, RAID 등의 장치를 네트워크로 묶고 데이터 접근을 위한 서버를 두는 형태이다. 즉, 저장장치에 필요한 장치를 네트워크로 묶어 하나의 시스템을 구성한다. → 데이터의 공유, 백업, 보안 등이 서버를 통해 자동으로 이루어지므로 사용자가 파일 관리에 특별히 신경쓸 일이 없다.
- 시스템이 제공하는 인터페이스를 통해 데이터에 접근한다.
- NAS보다 구축 비용이 많이 든다. 따라서 큰 회사의 시스템이나 대형 웹 시스템에 적합하다.

# 디스크 스케줄링

트랙의 이동을 최소화하여 **디스크 탐색 시간을 줄이는 것**이 목표이다.

## FCFS 디스크 스케줄링

- 가장 단순한 디스크 스케줄링 방식
- 요청이 들어온 트랙 순서대로 서비스한다.

<br>

## SSTF 디스크 스케줄링

- 현재 헤드가 있는 위치에서 가장 가까운 트랙부터 서비스한다.
- 만약 다음에 서비스할 두 트랙의 거리가 같다면 먼저 요청받은 트랙을 서비스한다.
- 효율성은 좋지만 아사 현상이 일어날 수 있다. 헤드가 중간에 위치하면 가장 안쪽이나 가장 바깥쪽에 있는 트랙을 서비스 받을 확률이 낮아지기 때문이다.
- 아사 현상으로 인해 공평성을 위배하여 잘 사용되지 않으나, 일괄 작업 시스템과 같은 다른 프로세스에 영향을 주지 않는 시스템에서는 사용되기도 했다.

<br>

## 블록 SSTF 디스크 스케줄링

- SSTF 디스크 스케줄링의 공평성 위배를 어느 정도 해결한 방법이다.
- 큐에 있는 트랙 요청을 일정한 블록 형태로 묶어 스케줄링한다. 모든 트랙이 블록 안에서만 움직인다. SSTF 스케줄링이 현재 트랙에서 가장 먼 트랙을 큐의 맨 끝으로 이동시킨다면, 블록 SSTF 스케줄링은 현재 트랙에서 가장 먼 트랙을 블록의 끝으로만 이동시킨다. 따라서 에이징이 적용되었으며 멀리 있는 트랙도 몇 번 양보하면 서비스 받을 수 있다.
- 에이징을 사용하여 공평성을 보장하지만, 성능은 FCFS만큼 안 좋다.

<br>

## SCAN 디스크 스케줄링

- SSTF 디스크 스케줄링의 공평성 위배 문제를 완화하기 위해 만들어졌다.
- 헤드가 한 방향으로만 움직이면서 서비스한다. 즉, 헤드가 움직이기 시작하면 맨 마지막 트랙에 도착할 때까지 뒤돌아가지 않고 게속 앞으로만 전진하면서 요청받은 트랙을 서비스한다.
- 엘리베이터 기법이라고도 부른다.
- **SSTF 디스크 스케줄링보다 공평성을 덜 위배하면서도 성능이 좋기 때문에, 많이 사용되는 기법 중 하나이다.**
- 동일한 트랙이나 실린더 요청이 연속적으로 발생하면 헤드가 더 이상 나아가지 못하고 제자리에 머물게 되어 바깥쪽 트랙이 아사 현상을 겪을 수 있다.

<br>

## C-SCAN 디스크 스케줄링

- SCAN 디스크 스케줄링을 변형하여 공평성 위배를 해결한다.
- 헤드가 한쪽 방향으로 움직일 때는 요청받은 트랙을 서비스하고 반대 방향으로 돌아올 때는 서비스하지 않고 이동만 한다.
- 작업없이 헤드를 이동하는 것이 매우 비효율적이고, 동일한 트랙 요청이 연속적으로 발생하면 SCAN 스케줄링과 마찬가지로 바깥쪽 트랙이 아사 현상을 겪는다.
- 잘 사용되지 않는다.

<br>

## LOOK 디스크 스케줄링

- `SCAN 디스크 스케줄링`의 불필요한 부분을 제거하여 효율을 높인 기법이다. `SCAN 스케줄링`에서는 트랙 요청이 없어도 헤드가 맨 마지막 트랙에 도착한 후에야 방향을 바꾸지만, `LOOK 스케줄링`에서는 더 이상 서비스할 트랙이 없으면 헤드가 끝까지 가지 않고 중간에서 방향을 바꾼다.
- **SCAN 디스크 스케줄링보다 성능이 좋아 많이 사용된다.**

<br>

## C-LOOK 디스크 스케줄링

- `C-SCAN 디스크 스케줄링`의 LOOK 버전이다.
- `C-SCAN 스케줄링`의 경우 더이상 서비스할 트랙이 없어도 헤드가 중간에서 방향을 바꾸지 않지만, `C-LOOK 스케줄링`의 경우 **더이상 서비스할 트랙이 없으면 헤드가 중간에서 방향을 바꿀 수 있다.**

<br>

## SLTF 디스크 스케줄링

- 최소 지연 우선 기법이다.
- 헤드가 고정된 저장장치에 사용하며, 많이 사용되지 않는다.
- 작업 요청이 들어온 섹터의 순서를 디스크가 회전하는 방향에 맞추어 다시 정렬한다.

<br>

# RAID

- 자동으로 백업을 하고 장애가 발생하면 이를 복구하는 시스템
- 동일한 규격의 디스크를 여러 개 모아 구성하며, 장애가 발생했을 때 데이터 복구에 사용한다.
- 하나의 원본 디스크와 같은 크기의 백업 디스크에 같은 내용을 동시에 저장하고, 하나의 디스크가 고장났을 때 다른 디스크를 사용하여 데이터를 복구한다.

## RAID 0 (스트라이핑)

- 병렬로 연결된 여러 개의 디스크에 데이터를 동시에 입출력할 수 있도록 구성된다.
- **같은 규격의 디스크를 병렬로 연결**하여 **여러 개의 데이터를 여러 디스크에 동시에 저장하거나 가져올 수 있다.**
- **장애 발생 시 복구하는 기능이 없기 때문에 장애가 발생하면 데이터를 잃는다.**
- 입출력 속도가 빠르다.

## RAID 1 (미러링)

- 하나의 데이터를 2개의 디스크에 나누어 저장하여 장애 시 백업 디스크로 활용한다.
- 데이터가 똑같이 여러 디스크에 복사되기 때문에 미러링이라고 부른다.
- 같은 크기의 디스크를 최소 2개 이상 필요로 하며 짝수 개의 디스크로 구성된다.
- 같은 데이터를 여러 디스크에 저장하기 때문에 장애 발생 시 미러링된 디스크를 활용하여 데이터를 복구할 수 있다.
- 저장하는 데이터와 같은 크기의 디스크가 하나 더 필요하기 때문에 비용이 증가한다.
- 같은 내용을 두 번 저장하기 때문에 속도가 느려진다. 때문에 데이터 입출력이 없는 시점에 백업이 이루어지도록(배치?) 조정하는 것이 좋다.

## RAID 2

- 오류 검출 기능이 없는 디스크에 대해 `오류 교정 코드`를 따로 관리하고, 오류가 발생하면 이 코드를 이용하여 디스크를 복구한다.
    - 오류 검출 코드: 오류가 발생한 원인을 알 수 있다. Ex:) 패리티 비트
    - `오류 교정 코드`: 오류가 발생했는지 확인하는 동시에 오류를 교정할 수 있는 코드이다. Ex:) 허밍 코드
- 데이터를 비트 단위로 분리하여 여러 개의 디스크에 나누어 저장한다. 이는 각 비트의 `오류 고정 코드`를 구성하여 나중에 비트 단위로 복구하기 위해서이다. 비트별로 만들어진 `오류 교정 코드`는 별도의 디스크에 저장되어 장애 발생 시 데이터 복구에 이용된다.
- n개의 디스크에 대해 오류 교정 코드를 저장하기 위한 **n-1개의 추가 디스크**를 필요로 한다. `RAID 1`보다 적은 저장 공간을 요구한다.
- **오류 교정 코드를 계산하는 데 많은 시간이 소비되어, 잘 사용되지 않는다.**

## RAID 3

- `RAID 4`와 같이 `오류 검출 코드`인 `패리티 비트`를 사용하여 데이터를 복구한다.
- `RAID 2`와 같이 데이터를 여러 개의 디스크에 나누어 저장하지만, 섹터 단위로 데이터를 나누어 저장한다.
- `N-way 패리티 비트 방식`을 사용한다. 이는 오류 검출에 사용하는 패리티 비트를 여러 섹터끼리 묶어서 구성하여, 오류가 없는 섹터를 이용하여 오류가 있는 섹터의 데이터를 복원하는 방법이다.
- `N-way 패리티 비트 방식`을 구성한 후 데이터 디스크가 아닌 별도의 디스크에 보관함으로써 장애 발생 시 오류를 복구한다.
- 일반적으로 `오류 검출 코드`의 크기가 오류 정정 코드보다 작기 때문에 RAID 3에서 추가되는 디스크의 양은 4개의 디스크당 1개 정도이다.
- 추가되는 디스크 양은 적지만 `N-way 패리티 비트`를 구성하는 데 필요한 계산량이 많다.

## RAID 4

- `RAID 3`와 같이 `오류 검출 코드`인 `패리티 비트`를 사용하여 데이터를 복구한다.
- `RAID 3`와 같이 `패리티 비트`를 추가하기 위한 계산량이 많다.
- `RAID 3`와 달리 데이터를 하나의 디스크에 블록 단위로 저장하고 패리티 비트를 블록과 연결하여 구성한다.
- `RAID 0`와 달리 추가되는 디스크의 양은 적다. 4개의 디스크당 1개의 추가 디스크만 있으면 된다.
- 데이터가 저장되는 디스크와 패리티 비트가 저장되는 디스크만 동작한다.

## RAID 5

- `RAID 4`를 사용하지 않는 이유는 병목 현상 때문이다. `RAID 4`에서는 모든 `패리티 비트`가 하나의 디스크에 저장되기 때문에 입출력이 일어날 때마다 `패리티 비트` 디스크에 데이터가 저장되어 `병목 현상`이 발생한다. 또한 `패리티 비트`가 저장된 디스크와 다른 디스크에서 동시에 장애가 발생할 경우 복구가 안 된다.
- 패리티 비트를 여러 디스크에 분산하여 구성한다.
    - `RAID 4`와 같은 방법을 사용하지만 병목 현상을 해결했다.
    - 패리티 비트를 해당 데이터가 없는 디스크에 보관하여, **패리티 비트가 있는 디스크가 고장나도 다른 디스크에 있는 패리티 비트를 이용하여 데이터를 복구할 수 있다.**

## RAID 6

- `RAID 5`와 같은 방식이지만 패리티 비트가 2개이다.
- `RAID 5`의 경우 한 디스크에 장애가 발생했을 때는 복구가 가능하지만 디스크 2개에 동시에 장애가 발생했을 때는 복구가 불가능하다. 디스크 2개에 동시에 장애가 발생하면 패리티 비트가 사라지기 때문이다. `RAID 6`은 이러한 문제를 해결하기 위해 패리티 비트를 2개로 구성하여 분산하여, 디스크 2개에 동시에 장애가 발생해도 복구할 수 있다.
- `패리티 비트`를 2개씩 운영하기 때문에 `RAID 5`보다 **계산량이 많고, 4개의 디스크당 2개의 추가 디스크가 필요하다.**

## RAID 10

- 하드디스크의 가격이 내려가면서 RAID 시스템은 추가되는 디스크의 수보다 빠른 입출력과 복구에 중점을 두게 되었다.
- `RAID 10`은 빠른 입출력이 장점인 `RAID 0`과 복구 기능을 가진 `RAID 1`을 결합한 것이다.

## RAID 50과 60

- `RAID 50`은 `RAID 5`로 묶은 두 쌍을 다시 `RAID 0`으로 묶어 사용한다.
- `RAID 60`은 `RAID 6`으로 묶은 두 쌍을 다시 `RAID 0`으로 묶어 사용한다. `RAID 60`에서 두 번째 패리티 비트를 빼면 `RAID 50`이 된다.

<br>

# 질문 목록

- 폴링이 무엇인가요?
- DMA가 무엇인가요?
- 인터럽트가 무엇인가요?
- 버퍼가 무엇인가요?